{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 04\n",
        "subtitle: \"Regression Analysis in Pyspark\"\n",
        "author:\n",
        "  - name: Tracy Anyasi\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2025-10-08'\n",
        "date-modified: today\n",
        "date-format: long\n",
        "format:\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "\n",
        "execute:\n",
        "  echo: false\n",
        "  eval: false\n",
        "  freeze: auto\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---This is Diagnostic check, No need to print it in the final doc---\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n",
            "|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n",
            "|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n",
            "|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n",
            "|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook+notebook_connected+vscode\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "# df.printSchema() # comment this line when rendering the submission\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove incomplete data, keep relevant variables, and iron out complicated string values\n",
        "Encoder turns categorical columns (remote, hybrid, onsite) to numeric ones (1 or 0) based on input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| eval: true\n",
        "#| echo: falase\n",
        "#| fig-align: center\n",
        "\n",
        "from pyspark.sql.functions import col, pow, when\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "#remove rows with NAs\n",
        "df_cleaned = df.dropna(subset=[\n",
        "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"STATE_NAME\", \"EMPLOYMENT_TYPE_NAME\",\n",
        "    \"REMOTE_TYPE_NAME\", \"MIN_EDULEVELS_NAME\", \"DURATION\", \n",
        "    \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"\n",
        "])\n",
        "\n",
        "eda_cols = [\n",
        "    \"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"DURATION\", \"COMPANY_IS_STAFFING\",\n",
        "    \"IS_INTERNSHIP\", \"STATE_NAME\", \"REMOTE_TYPE_NAME\",\n",
        "    \"EMPLOYMENT_TYPE_NAME\", \"MIN_EDULEVELS_NAME\"\n",
        "]\n",
        "df_cleaned = df_cleaned.select(eda_cols)\n",
        "\n",
        "#clean up REMOTE_TYPE_NAME and reduce the different inputs\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Premise\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On Premise\")\n",
        "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "#clean EMPLOYMENT_TYPE_NAME\n",
        "df_cleaned = df_cleaned.withColumn(\n",
        "    \"EMPLOYMENT_TYPE_NAME\",\n",
        "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Parttime\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Fulltime\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n",
        "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "#df_cleaned = df_cleaned.filter(col(\"REMOTE_TYPE_NAME\") != \"Undefined\") -- initially wnated to remove the undefined but it dropped the\n",
        "#percentage of the regression model\n",
        "\n",
        "# Categorical and numeric columns\n",
        "categorical_cols = [\"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\"]\n",
        "continuous_cols = [\"MIN_YEARS_EXPERIENCE\", \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"]\n",
        "\n",
        "# Index and One-Hot Encode\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_Idx\", handleInvalid=\"skip\") for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=f\"{col}_Idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------------------------+-------------------------------------------+\n",
            "|SALARY|features                              |features_poly                              |\n",
            "+------+--------------------------------------+-------------------------------------------+\n",
            "|192800|(9,[0,1,4,6],[6.0,55.0,1.0,1.0])      |(10,[0,1,4,6,9],[6.0,55.0,1.0,1.0,36.0])   |\n",
            "|125900|(9,[0,1,4,6],[12.0,18.0,1.0,1.0])     |(10,[0,1,4,6,9],[12.0,18.0,1.0,1.0,144.0]) |\n",
            "|118560|[5.0,20.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0]|[5.0,20.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,25.0]|\n",
            "|192800|(9,[0,1,4,6],[6.0,55.0,1.0,1.0])      |(10,[0,1,4,6,9],[6.0,55.0,1.0,1.0,36.0])   |\n",
            "|116500|(9,[0,1,4,6],[12.0,16.0,1.0,1.0])     |(10,[0,1,4,6,9],[12.0,16.0,1.0,1.0,144.0]) |\n",
            "+------+--------------------------------------+-------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# combines all categorical and numeric columns into one vector coulmn\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=continuous_cols + [f\"{col}_vec\" for col in categorical_cols],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "#create pipeline for sequential transformation\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "data = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "\n",
        "# polynomial regression for MIN_YEARS_EXPERIENCE\n",
        "data = data.withColumn(\"MIN_YEARS_EXPERIENCE_SQ\", pow(col(\"MIN_YEARS_EXPERIENCE\"), 2))\n",
        "\n",
        "#assemble og features plus poly feature into new feature vector\n",
        "assembler_poly = VectorAssembler(\n",
        "    inputCols=[\"features\", \"MIN_YEARS_EXPERIENCE_SQ\"],\n",
        "    outputCol=\"features_poly\"\n",
        ")\n",
        "data = assembler_poly.transform(data)\n",
        "\n",
        "#split data into training and testing sets for model evaluation\n",
        "reg_train, reg_test = data.randomSplit([0.8, 0.2], seed=51)\n",
        "#This split reserves 80% of the data for training and 20% for testing which provides enough data for the model to learn while keeping a reliable holdout set for evaluation.\n",
        "\n",
        "#displays final structure with salary as target\n",
        "data.select(\"SALARY\", \"features\", \"features_poly\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mapping for EMPLOYMENT_TYPE_NAME:\n",
            "  Index 0 -> Fulltime\n",
            "  Index 1 -> Parttime\n",
            "  Index 2 -> Flexible\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 340:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mapping for REMOTE_TYPE_NAME:\n",
            "  Index 0 -> Undefined\n",
            "  Index 1 -> Remote\n",
            "  Index 2 -> Hybrid\n",
            "  Index 3 -> On Premise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "for col in categorical_cols:\n",
        "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_Idx\", handleInvalid=\"skip\")\n",
        "    model = indexer.fit(df_cleaned)\n",
        "    print(f\"\\nMapping for {col}:\")\n",
        "    for i, category in enumerate(model.labels):\n",
        "        print(f\"  Index {i} -> {category}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/10/05 19:25:01 WARN Instrumentation: [b8b5abf9] regParam is zero, which might cause numerical instability and overfitting.\n",
            "[Stage 350:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R² Score: 0.2840\n",
            "RMSE: 35315.94\n",
            "MAE: 27676.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd\n",
        "from scipy.stats import t\n",
        "\n",
        "lin_reg = LinearRegression(featuresCol=\"features\", labelCol=\"SALARY\")\n",
        "\n",
        "lin_reg_fit = lin_reg.fit(reg_train) #fit model to training data\n",
        "\n",
        "salary_pred = lin_reg_fit.transform(reg_test) #predicting on test data\n",
        "\n",
        "#define the evaluators\n",
        "r2_eval = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "rmse_eval = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "mae_eval = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "\n",
        "#generate metrics\n",
        "r2_score = r2_eval.evaluate(salary_pred)\n",
        "rmse_val = rmse_eval.evaluate(salary_pred)\n",
        "mae_val = mae_eval.evaluate(salary_pred)\n",
        "\n",
        "print(f\"R² Score: {r2_score:.4f}\")\n",
        "print(f\"RMSE: {rmse_val:.2f}\")\n",
        "print(f\"MAE: {mae_val:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Coefficient Summary:\n",
            "                  Feature      Estimate    Std Error     t-Stat       p-Value  \\\n",
            "0               Intercept  76735.577948   102.356000  66.277489  0.000000e+00   \n",
            "1    MIN_YEARS_EXPERIENCE   6783.898664    23.632630  -1.831651  6.702934e-02   \n",
            "2                DURATION    -43.286721  6866.446762  -1.025459  3.051684e-01   \n",
            "3           IS_INTERNSHIP  -7041.257613  1063.265929  -0.595172  5.517402e-01   \n",
            "4     COMPANY_IS_STAFFING   -632.826152  3011.540238  -0.421858  6.731367e-01   \n",
            "5  EMPLOYMENT_TYPE_NAME_A  -1270.441524  3605.833255  -1.077711  2.811853e-01   \n",
            "6  EMPLOYMENT_TYPE_NAME_B  -3886.046755  2462.498142   3.306373  9.480161e-04   \n",
            "7      REMOTE_TYPE_NAME_X   8141.937756  2529.947825   3.635882  2.782402e-04   \n",
            "8      REMOTE_TYPE_NAME_Y   9198.592476  3172.252546   7.636575  2.398082e-14   \n",
            "9      REMOTE_TYPE_NAME_Z  24225.144004  3579.670705  21.436491  0.000000e+00   \n",
            "\n",
            "   95% CI Lower  95% CI Upper  \n",
            "0  76534.942765  76936.213130  \n",
            "1   6737.574686   6830.222643  \n",
            "2 -13502.691172  13416.117730  \n",
            "3  -9125.439821  -4957.075405  \n",
            "4  -6535.957638   5270.305334  \n",
            "5  -8338.488484   5797.605435  \n",
            "6  -8712.962276    940.868767  \n",
            "7   3182.809376  13101.066136  \n",
            "8   2980.437509  15416.747443  \n",
            "9  17208.380095  31241.907914  \n"
          ]
        }
      ],
      "source": [
        "#getting coefs and stats\n",
        "model_summary = lin_reg_fit.summary\n",
        "\n",
        "coefs = lin_reg_fit.coefficients\n",
        "intercept_val = lin_reg_fit.intercept\n",
        "stderr = model_summary.coefficientStandardErrors\n",
        "t_vals = model_summary.tValues\n",
        "p_vals = model_summary.pValues\n",
        "\n",
        "#compute degrees of freedom for t-distribution\n",
        "n_obs = model_summary.numInstances\n",
        "num_features = len(coefs)\n",
        "dfree = n_obs - num_features - 1\n",
        "\n",
        "#critical t-value for 95% CI\n",
        "t_crit = t.ppf(0.975, dfree)\n",
        "\n",
        "feature_labels = [\n",
        "    \"MIN_YEARS_EXPERIENCE\",\n",
        "    \"DURATION\",\n",
        "    \"IS_INTERNSHIP\",\n",
        "    \"COMPANY_IS_STAFFING\",\n",
        "    \"EMPLOYMENT_TYPE_NAME_A\",\n",
        "    \"EMPLOYMENT_TYPE_NAME_B\",\n",
        "    \"REMOTE_TYPE_NAME_X\",\n",
        "    \"REMOTE_TYPE_NAME_Y\",\n",
        "    \"REMOTE_TYPE_NAME_Z\"\n",
        "]\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": [\"Intercept\"] + feature_labels,\n",
        "    \"Estimate\": [intercept_val] + coefs.tolist(),\n",
        "    \"Std Error\": stderr,\n",
        "    \"t-Stat\": t_vals,\n",
        "    \"p-Value\": p_vals\n",
        "})\n",
        "\n",
        "#add confidence intervals\n",
        "coef_table[\"95% CI Lower\"] = coef_table[\"Estimate\"] - t_crit * coef_table[\"Std Error\"]\n",
        "coef_table[\"95% CI Upper\"] = coef_table[\"Estimate\"] + t_crit * coef_table[\"Std Error\"]\n",
        "\n",
        "print(\"\\nCoefficient Summary:\")\n",
        "print(coef_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The linear regression model explains approximately 28% of the variance in salaries, showing that while job attributes like as experience and remote status influence pay, substantial variation remains unexplained. This is likely due to qualitative factors like role seniority, company size, or negotiation effects. Undefined roles were initally excluded but that reduced the model's reliabilty and was subsequentially added as a baseline for remote roles.\n",
        "\n",
        "Some statistically significant predictors include remote and hybrid roles (Remote Type X & Y) and Flexible employment type, all of which show clear positive or negative salary impacts. Compared to the baseline groups (Fulltime employment and Undefined remote), Flexible roles pay significantly less than Fulltime roles, whereas Parttime roles do not show a significant difference. For remote types, Remote, Hybrid, and On Premise roles show meaningful salary increases relative to Undefined roles, with On Premise roles exhibiting the largest premium of approximately $24K. \n",
        "\n",
        "Non-significant coefficients, such as Parttime or certain remote categories, suggest that observed differences may be due to random variation rather than a true effect, while the significant predictors highlight areas where job structure meaningfully affects compensation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polynominal Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/10/05 19:26:06 WARN Instrumentation: [6e0fc769] regParam is zero, which might cause numerical instability and overfitting.\n",
            "25/10/05 19:26:10 WARN Instrumentation: [6e0fc769] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
            "[Stage 356:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polynomial Regression R²: 0.3114361363313357\n",
            "Polynomial Regression RMSE: 34631.812165496616\n",
            "Polynomial Regression MAE: 26847.381847776545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import PolynomialExpansion\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "reg_train = reg_train.drop(\"features_poly\")\n",
        "reg_test = reg_test.drop(\"features_poly\")\n",
        "\n",
        "# Assuming your original features column is \"features\"\n",
        "polyExpansion = PolynomialExpansion(degree=2, inputCol=\"features\", outputCol=\"features_poly\")\n",
        "\n",
        "train_poly = polyExpansion.transform(reg_train)\n",
        "test_poly = polyExpansion.transform(reg_test)\n",
        "\n",
        "\n",
        "poly_lr = LinearRegression(featuresCol=\"features_poly\", labelCol=\"SALARY\")\n",
        "poly_model = poly_lr.fit(train_poly)\n",
        "\n",
        "\n",
        "predictions_poly = poly_model.transform(test_poly)\n",
        "\n",
        "#define the evaluators\n",
        "r2_eval = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "rmse_eval = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "mae_eval = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "\n",
        "#generate metrics\n",
        "r2 = r2_eval.evaluate(predictions_poly)\n",
        "rmse = rmse_eval.evaluate(predictions_poly)\n",
        "mae = mae_eval.evaluate(predictions_poly)\n",
        "\n",
        "print(f\"Polynomial Regression R²: {r2}\")\n",
        "print(f\"Polynomial Regression RMSE: {rmse}\")\n",
        "print(f\"Polynomial Regression MAE: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "ename": "UnsupportedOperationException",
          "evalue": "No Std. Error of coefficients available for this LinearRegressionModel",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnsupportedOperationException\u001b[39m             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m coefficients = poly_model.coefficients\n\u001b[32m      5\u001b[39m intercept = poly_model.intercept\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m std_errors = \u001b[43msummary_poly\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoefficientStandardErrors\u001b[49m\n\u001b[32m      7\u001b[39m t_values = summary_poly.tValues\n\u001b[32m      8\u001b[39m p_values = summary_poly.pValues\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/assignment-04-tanyasiii/.venv/lib/python3.12/site-packages/pyspark/ml/regression.py:705\u001b[39m, in \u001b[36mLinearRegressionSummary.coefficientStandardErrors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcoefficientStandardErrors\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    692\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    693\u001b[39m \u001b[33;03m    Standard error of estimated coefficients and intercept.\u001b[39;00m\n\u001b[32m    694\u001b[39m \u001b[33;03m    This value is only available when using the \"normal\" solver.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    703\u001b[39m \u001b[33;03m    LinearRegression.solver\u001b[39;00m\n\u001b[32m    704\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_java\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoefficientStandardErrors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/assignment-04-tanyasiii/.venv/lib/python3.12/site-packages/pyspark/ml/util.py:254\u001b[39m, in \u001b[36mtry_remote_call.<locals>.wrapped\u001b[39m\u001b[34m(self, name, *args)\u001b[39m\n\u001b[32m    252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m deserialize(properties)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/assignment-04-tanyasiii/.venv/lib/python3.12/site-packages/pyspark/ml/wrapper.py:87\u001b[39m, in \u001b[36mJavaWrapper._call_java\u001b[39m\u001b[34m(self, name, *args)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     86\u001b[39m java_args = [_py2java(sc, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/assignment-04-tanyasiii/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/assignment-04-tanyasiii/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[31mUnsupportedOperationException\u001b[39m: No Std. Error of coefficients available for this LinearRegressionModel"
          ]
        }
      ],
      "source": [
        "from scipy.stats import t\n",
        "\n",
        "summary_poly = poly_model.summary\n",
        "coefficients = poly_model.coefficients\n",
        "intercept = poly_model.intercept\n",
        "std_errors = summary_poly.coefficientStandardErrors\n",
        "t_values = summary_poly.tValues\n",
        "p_values = summary_poly.pValues\n",
        "\n",
        "#degrees of freedom\n",
        "n = summary_poly.numInstances\n",
        "p = len(coefficients)\n",
        "dof = n - p - 1\n",
        "\n",
        "#critical t-value for 95% CI\n",
        "critical_value = t.ppf(0.975, dof)\n",
        "\n",
        "feature_labels = [\n",
        "    \"MIN_YEARS_EXPERIENCE\",\n",
        "    \"DURATION\",\n",
        "    \"IS_INTERNSHIP\",\n",
        "    \"COMPANY_IS_STAFFING\",\n",
        "    \"EMPLOYMENT_TYPE_NAME_A\",\n",
        "    \"EMPLOYMENT_TYPE_NAME_B\",\n",
        "    \"REMOTE_TYPE_NAME_X\",\n",
        "    \"REMOTE_TYPE_NAME_Y\",\n",
        "    \"REMOTE_TYPE_NAME_Z\"\n",
        "]\n",
        "\n",
        "#create df\n",
        "coef_poly_df = pd.DataFrame({\n",
        "    \"Feature\": [\"Intercept\"] + [f\"PolyFeature_{i}\" for i in range(p)],\n",
        "    \"Coefficient\": [intercept] + coefficients.tolist(),\n",
        "    \"Std Error\": std_errors,\n",
        "    \"t-value\": t_values,\n",
        "    \"p-value\": p_values\n",
        "})\n",
        "\n",
        "#add confidence intervals\n",
        "coef_poly_df[\"95% CI Lower\"] = coef_poly_df[\"Coefficient\"] - critical_value * coef_poly_df[\"Std Error\"]\n",
        "coef_poly_df[\"95% CI Upper\"] = coef_poly_df[\"Coefficient\"] + critical_value * coef_poly_df[\"Std Error\"]\n",
        "\n",
        "print(coef_poly_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
